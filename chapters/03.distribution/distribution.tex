\section{Handling the Data Volume}\label{volume}
The new data volume is a challenge to process for both algorithms and computing infrastructure. Push for parallel and distributed algorithms. For Radio Interferometer imaging, we require specialized algorithms. The two distinct operations, non-uniform FFT and Deconvolution, were difficult algorithms for parallel or distributed computing.

The non-uniform FFT was historically what dominated the runtime \cite{}. Performing an efficient non-uniform FFT for Radio Interferometers is an active field of research\cite{offringa2014wsclean, pratley2018fast}, continually reducing the runtime costs of the operation. Recently, Veeneboer et al\cite{veenboer2017image} developed a non-uniform FFT which can be fully executed on the GPU. It speeds up the most expensive operation.

In radio Astronomy, CLEAN is the go-to deconvolution algorithm. It is highly iterative in nature and therefore difficult to implement for parallel or distributed computing. Nevertheless, the light-weight nature of CLEAN has left it as a comparatively cheap algorithm. But with the advent of GPU non-uniform FFT, it has also been modified for more parallel computing\cite{parallelCLEAN}.

\subsection{Fully distributed imaging algorithm}

The final push is towards distributed computing. The non-uniform FFT has been difficult to distribute. The Image Domain Gridding Algorithm 

It was difficult in the old days, because fully distributing the non-uniform FFT was not known, and a distributed CLEAN algorithm unnecessary. But with the new image domain gridding algorithm, we can use it to derive a distributed non-uniform FFT. For the deconvolution we can use compressed sensing based algorithms and derive a 

Deconvolution algorithms which use the Theory of Compressed Sensing, producing higher quality results. The difficulty so far was to have a comparable runtime to CLEAN.




