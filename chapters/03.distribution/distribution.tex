\section{Coordinate descent deconvolution}\label{cd}
Coordinate descent methods are a family of algorithms. Various variants exist\cite{richtarik2014iteration, richtarik2016distributed, richtarik2016parallel}, but they share one common idea: Most of our problems become simple when we reduce the number of dimensions. Deconvolving a whole image is difficult. But deconvolving a single pixel is easy. As we will show in section \ref{cd:deriving}, we can derive a closed form solution\footnote{Deriving a formula which we can implement in a few lines of code.} for deconvolving a single pixel. We then iterate over all pixels, possibly several times, until we converge to a deconvolved image. 

This is the idea behind coordinate descent methods. By reducing the dimensions of the problem, we can often find an optimization algorithm where each iteration is "cheap" to compute. In these cases, coordinate descent methods produce competitive results\cite{nesterov2012efficiency, nesterov2013gradient}.

For a deconvolution algorithm in radio astronomy, we need three parts: An optimization algorithm, a regularization, and an optimization objective. We use coordinate Descent as the optimization algorithm, take Elastic Net as the regularization and use the following objective function:

\begin{equation}\label{cd:deconv}
\underset{x}{minimize} \: \left \| I_{dirty} - x * PSF \right \|_2^2 + \lambda ElasticNet(x)
\end{equation}

As we have shown before, the objective function consists of two parts. The data term $\left \| I_{dirty} - x * PSF \right \|_2^2$ and the regularization term $ElasticNet(x)$. The data term forces the image to be as close to the measurements as possible which forces the image to be as close to the measurements as possible, the regularization term forces the image to be as consistent as possible with our prior knowledge. The parameter $\lambda$ is a weight that either forces more or less regularization. It is left to the user to define for each image. We will derive the coordinate descent algorithm that optimizes the objective \eqref{cd:deconv} in section \ref{cd:deriving}. First, let us explain what the elastic net regularization does.

\subsection{Elastic net regularization} \label{cd:reg}
This regularization is a mixture between the L1 and L2 regularization. The figure \ref{cd:elastic} shows the effect of the L1 and L2 norm on a single star. The L1 regularization forces the image to contain few non-zero pixels as possible. It encodes our prior knowledge that the image will contain stars.

T

The L2 regularization, but it is not sparse. L2 norm was used in other work. \cite{ferrari2014distributed}
By mixing L1 and L2, we create a "sparsifying L2 norm". 
May even speed up convergence for correlated pixel values compared to L1 or L2\cite{friedman2010regularization}. But was not investigated in this project

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth]{./chapters/03.distribution/L1.png}
		\caption{Effect of the pure L1 norm ($\lambda$ = 1.0) on a single point source.}
		\label{cd:elastic:L1}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth]{./chapters/03.distribution/L2.png}
		\caption{Effect of the pure L2 norm ($\lambda$ = 1.0) on a single point source.}
		\label{cd:elastic:L2}
	\end{subfigure}
	
	\caption{Effect of the L1 and L2 Norm separately.}
	\label{cd:elastic}
\end{figure}

Formally, elastic net regularization is defined as the following:
\begin{equation}\label{cd:elastic:formula}
ElasticNet(x) = \: \alpha \left \|x \right \|_1 + \frac{1-\alpha}{2}  \left \|x \right \|_2
\end{equation}

Where $\alpha$ is between 0 and 1, and represents the mixture coefficient between the two norms.

Implementation, closed form solution.


\subsection{Deriving the basic coordinate descent deconvolution algorithm}\label{cd:deriving}
Coordinate Descent has gained more interest, because it may exploit sparse structures in the data.

Different versions.
Optimization for large data volume\cite{richtarik2016distributed}

4 multiplications and additions only\cite{richtarik2012efficient}

error tolerance O( n ËœLR / e ), \cite{richtarik2016parallel}




Monotone decreasing.
Robust
Many different variants.

Outperforms other algorithms like Gradient based methods, FISTA and ADMM if a single iteration (minimizing a single pixel in our case) is "cheap" to compute. 
How fast it is in practice depends on the regularization $P(x)$ we use.

The basic algorithm is as follows in pseudocode: A major cycle has calculated the dirty image and the $PSF$. We do not care yet about computation speed.

Because it is a separable objective function, we can handle ElasticNET() seperately

\begin{lstlisting}
dirty = IFFT(Gridding(visibilities))
residuals = dirty

x = new Array
objectiveValue = SUM(residuals * residuals) + P(x)
oldObjectiveValue = objectiveValue

do 
{
	oldObjectiveValue = objectiveValue

	//the core of the algorithm
	pixelLocation = IterationStrategy(residuals)
	optimalValue = Minimize(residuals, psf, pixelLocation)
	optimalValue = ApplyElasticNet(optimalValue)
	
	//housekeeping
	x[pixelLocation] += optimalValue
	residuals = (dirty - Convolve(x, psf))
	objectiveValue = SUM(residuals * residuals) + lambda * ElasticNet(x)
} while (oldObjectiveValue - objectiveValue)  < epsilon
\end{lstlisting}

The core of the algorithm consists of three functions: $IterationStrategy$ which selects a pixel to optimize according to some strategy, $Minimize()$ which then finds the minimum value of the pixel, and $ApplyElasticNet()$ , which finds the regularized value of the pixel according to the Elastic Net regularization. First we discuss the iteration strategy and derive the  $Minimize()$ function is in our deconvolution task. How the function $ApplyElasticNet()$ looks is discussed in section section \ref{dist:deconv:reg}.

From the viewpoint of numerical optimization, Minimize is always an "implementation" detail of the algorithm.

The iteration strategy
\begin{itemize}
	\item Random
	\item Cyclic
	\item Greedy
\end{itemize}
Random 
he next point is the iteration strategy. This is where Coordinate Descent methods are robust. They are proven to converge by simply choosing randomly. Or a greedy strategy where the pixel which reduces the objective \eqref{dist:deconv} by the largest amount. It was proven to converge for a variety of strategies. For this project, we are interested in which takes fewer computing resources to converge. 
Start with a greedy scheme, well known convergence guarantees at least linearly (with respect to iteration count?)\cite{luo1992convergence}
Cyclic scheme.

The task of the $Minimize()$ function is to reduce the data term of the objective \eqref{dist:deconv}, i.e. $\left \| I_{dirty} - x * PSF \right \|_2^2$. There are many different ways to implement $Minimize()$. For example,  we could use a line search algorithm, which tries different values for the pixel and saves the value with the lowest data objective. Luckily for our case we have a closed form solution. Meaning we have a formula that results in the optimal pixel value. It's derived from the fact that the data term reduces to a parabola when we only have one unknown pixel. The equation \eqref{dist:deconv:cd:derivation} derives the parabola from the data term, and the equation \eqref{dist:deconv:cd:minimizer} shows the closed form solution, where $\langle x, y\rangle$ is the inner product\footnote{As the reader is probably aware, there is no one inner product. Rather, there are several ways to define a valid inner product. Here we use the element-wise multiplication followed by a sum.}, the element-wise multiplication followed by a sum of the two vectors.

\begin{equation} \label{dist:deconv:cd:derivation}
\begin{split}
objective(pixel) & = \left \| I_{res} - PSF * pixel \right \|_2^2\\
objective(pixel) & = (I_{res} - PSF * pixel)^2\\
objective(pixel) & = \langle I_{res}, I_{res} \rangle - 2*\langle I_{res},PSF\rangle * pixel + \langle PSF, PSF \rangle * pixel^2\\
objective(pixel) & = \langle PSF, PSF \rangle * pixel^2 - 2*\langle I_{res},PSF\rangle * pixel + \langle I_{res}, I_{res} \rangle
\end{split}
\end{equation}

\begin{equation} \label{dist:deconv:cd:minimizer}
\begin{split}
f(x) & = a*x^2 \\
 & + b*x \\
 & + c\\
 \\
x_{min} & = \frac{-b}{2a}
\end{split}
\quad \quad
\begin{split}
objective(pixel) & = \langle PSF, PSF \rangle * pixel^2 \\
 & - 2*\langle I_{res},PSF\rangle * pixel \\
 &+ \langle I_{res}, I_{res} \rangle\\
 \\
pixel_{min} & = \frac{\langle I_{res},PSF\rangle}{\langle PSF, PSF \rangle}
\end{split}
\end{equation}

Note that the $PSF$ in \eqref{dist:deconv:cd:minimizer} is centred at the pixel we wish to minimize. Also, if the pixel is located at the edges of the image, it may be partially cut off. This fact becomes relevant as soon as we want to implement $Minimize()$ efficiently and pre-calculate the inner-products $\langle I_{dirty},PSF\rangle$ and $\langle PSF, PSF \rangle$. From here on forward, we use the terminology $b$-map to denote the pre-calculated inner products $\langle I_{dirty},PSF\rangle$ for each pixel, and $a$-map for all pre-calculated $\langle PSF, PSF \rangle$ products (from the fact that $x_{min} = \frac{-b}{2a}$). 


\subsubsection{Efficient Coordinate Descent implementation}\label{dist:deconv:efficient}
Coordinate Descent is only useful when one iteration is cheap to compute.

Pre-calculation of the two inner products
Efficiently



The question of efficient implementation. In the previous section, we have seen how coordinate descent works in general. But now we have to look at the details and see how we can implement it efficiently.

Question of convolution scheme. 
Circular convolution is physically not possible. The $PSF$ of the lower left corner does not wrap around the image and influence all other corners of the image. But as we will see, for an efficient coordinate descent we need to calculate a convolution to cache. The circular convolution is the output of the FFT. This is why reconstruction algorithms sometimes choose to use circular convolution \cite{ferrari2014distributed}.

The other convolution scheme, namely zero padding. We use this scheme. It results 

Iteration scheme. For a greedy iteration scheme, we would need to first:
\begin{enumerate}
	\item find the optimum pixel value for each pixel independently (i.e. $\frac{-b}{2a}$)
	\item evaluate which optimum pixel value results in the best reduction of the objective function \eqref{dist:deconv}
\end{enumerate}

For the first step, we can cache intermediate results and drastically reduce the computation. The second step can be approximated in a way that we do not need to evaluate the objective function.

\textbf{Pre-Calculating $b$- and $a$-maps}\\
Caching of intermediate results. We have seen in section \ref{dist:deconv:cd} how we can find the optimum for a single pixel. We need to calculate  $x_{opt} = \frac{-b}{2a}$ where  $b = -2 SUM( pixel*PSF*I_{dirty})$ and $a = SUM(PSF * PSF)$. First, we note that $a$ depends only on the $PSF$ which is constant, which means $a$ is also constant. However, this is not true depending on the convolution we use.
$PSF$ at the corner gets masked off, and the $a$ value changes.
We can calucalte a lookup map in linear time.
\begin{lstlisting}

\end{lstlisting}

How to cache $b$. Use correlation of the dirty image with the $PSF$. Then we have a lookup map. Can be done efficiently in the Fourier domain. But the question then becomes in how to update bMap efficiently.


Unsolved problem of varying $PSF^2$

\textbf{Approximating the objective function}\\
$a$ is constant in $\frac{-b}{2a}$



Putting it all together. Creating lookup maps for $a$ and $b$, and do not evalue the ojbective function.
\begin{lstlisting}
dirty = IFFT(Gridding(visibilities))

//pre-calculate bMap
dirtyPadded = ZeroPadding(dirty, psfSize)
fourierDirtyPadded = FFT(dirtyPadded)
fourierPsf = FFT(invert(psf))		//we require the correlation, that is why we invert the psf
bMap = IFFT(fourierDirtyPadded * fourierPsf)

//pre-calculate aMap. aMap stays constant over all CD iterations
aMap = 
 
x = new Array   
do 
{
	oldObjectiveValue = objectiveValue
	
	//the core of the algorithm
	pixelLocation = IterationStrategy(residuals)
	optimalValue = Minimize(residuals, pixelLocation)
	optimalValue = ApplyElasticNet(optimalValue)
	
	//housekeeping
	x[pixelLocation] = optimalValue
	residuals = (dirty - Convolve(x, psf))
	objectiveValue = SUM(residuals * residuals) + ElasticNet(x)
} while (oldObjectiveValue - objectiveValue)  < epsilon
\end{lstlisting}





\subsection{Major Cycle convergence}
Putting it all together

We have the Minor Cycle, which is easy to converge.

Coordinate Descent Path optimization \cite{friedman2010regularization}
Danger that CD takes too many pixel into a Major Cycle. Lower bound per iteration, PSF sidelobe
  can still be too low, danger when many psf sidelobes overlap

\subsection{Test on MeerKAT data}

\subsection{Distributed Deconvolution}
How do we distribute the major cycle. We need to distribute every step, Gridding, FFT and Deconvolution.

Gridding, Large number of input data. This needs to be distributed
We use the Image domain gridding introduces in sectionand use it as the basis for the distributed gridding.

The FFT is generally not worth distributing, if we can keep all the data in memory. When the gridding is done, in our setup, the grid is small enough to keep in memory. (cite distributed fftw)

Deconvolution is also worth distributing. CLEAN depending on the observation is the second most time consuming step. But gridding tends to be easier to distribute, so in some observations it is the most time consuming step.
Split the image into patches and deconvolve each patch.
Sadly not possible, we need communication. how we communicate is important.

We use a distributed Gridding and a distributed deconvolution. Which leads us to the following architecture.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.80\linewidth]{./chapters/03.distribution/distributed_architecture.png}
	\caption{Distributed architecture for half a major cycle}
	\label{dist:architecture:fig}
\end{figure}

Where each node is one computer, i.e. has its own, possibly multiple cpus and its shared memory.
Split the input visibilities onto nodes. 
Do the gridding locally on each node
Communicate the grid
inverse FFT on one node.
Communicate the patches of the image.
Deconvolve each patch and communicate
