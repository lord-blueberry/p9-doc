\section{Discussion}\label{discussion}
Problem of calibration.


CLEAN: MAsking as part for low noise. Maybe also works for Coordinate Descent

Figure \ref{results:gradients:update} shows that at major cycle index 4 (the fifth major cycle), all approximations except for $frac{1}{64}$ are within 0.09\% of the original solution. The current implementation stops when coordinate descent converges within 1000 iterations in the current major cycle. This rule may be too strict, and our coordinate descent algorithm may be stopped earlier. 

GPU Coordinate Descent

Difficult to achieve speedup with a dense $PSF$ we approximated

\subsection{Approximation of the $PSF$}
Approximation that works. To our knowledge we are the first to explore an approximated $PSF$. Not relevant for all optimization algorithm, but parallel coordinate descent methods achieve a (significant) speedup.

In our test we were able to use it without needing more major cycles than multi-scale CLEAN.

The need for major cycles could be further reduced. 
Question of effective heuristics that work for a wide range of 

Parallel deconvolutions

\subsection{Calibration errors}
Common experience that CLEAN based algorithms handle calibration errors better \cite{offringa2017optimized} than "proper" optimization algorithms.


It is a question why. We experienced similar results, but used a simple regularization: elastic net. Other algorithms like MORESANE\cite{dabbech2015moresane} use more sophisticated regularization.

Why does CLEAN work so well with calibration errors? Is there some sort of implicit regulariztion in the way it choses its pixels. (not in the actual regularization)



\subsection{CLEAN heuristics for coordinate descent}
Since CLEAN and coordinate descent methods are acting out similar things, we may be able to use CLEAN heuristics to improve coordinate descent based methods.

Masking: CLEAN uses masking to reconstruct sources below the noise level of the image. After a number of iterations, it masks all pixels which are not zero. (Ie. now all sources are detected) and clean deeper. 

Similar stuff can be done for coordinate descent methods. 

Greedy Coordinate descent

\subsection{Approx scales to large field of view}
Wide field of view observations are what Approx likes.

\subsection{Hydra}
our coordinate descent method is not distributed yet. Hydra exists. It is APPROX in the distributed environment.
We had to adapt the implementation of APPROX for the deconvolution problem. Similar adaptions necessary for a distributed algorithm. Problems of cold start, and irrelevant pixels.





\subsection{Multi frequency extension}\label{discussion:mfs}
Difficult.

Regularized inverse problem  \cite{ferrari2015multi}. Objective function 
How it works, adding a new term to the objective function

\begin{equation}\label{cd:deconv}
\underset{x}{minimize} \: \frac{1}{2} \left \| I_{dirty} - X * PSF \right \|_2^2 + \lambda ElasticNet(X) + \lambda_v \left \| DX \right \|_1
\end{equation}

Where $D$ is the Discrete cosine transform.

Does not have a proximal operator for each pixel. problem for Coordinate descent method.

Question if each iteration can be cheap.

But may be separated with respect to frequency with Lagrangian multipliers. Question if cd methods are faster.
