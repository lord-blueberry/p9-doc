\section{$PSF$ approximation for fast and distributed deconvolution} \label{gradients}
This section describes our main hypothesis of this work: We can further approximate the $PSF$ in the Major/Minor cycle and exploit it to speed up/distribute coordinate descent based deconvolution algorithms.

A deconvolution algorithm in the Major/Minor cycle works with a $PSF$, which is constant over the whole image. However, this is not the case for modern radio interferometers. The $w$-term in the visibility measurements modify the true $PSF$ over the image. This is why we need the Major cycle: After a number of iterations of the deconvolution algorithm, the Major cycle transforms the model image back to visibility measurements, and subtracts the model from the measured visibilities. Then, it transforms the residual visibilities back into image space. The gridder corrects for the $w$-term. It corrects the error the deconvolution algorithm introduces with a constant $PSF$. The Major cycle allows us to use an approximation of the true $PSF$ in the deconvolution. We believe this can be exploited to speed up/distribute the deconvolution.

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.245\linewidth}
		\includegraphics[width=\linewidth, clip, trim= 0.25in 0.25in 0.25in 0.25in]{./chapters/03.cd/simulated/psf.png}
		\caption{Full $PSF$}
	\end{subfigure}
	\begin{subfigure}[b]{0.245\linewidth}
		\includegraphics[width=\linewidth, clip, trim= 0.25in 0.25in 0.25in 0.25in]{./chapters/03.cd/simulated/psfCut.png}
		\caption{$\frac{1}{2}PSF$ approximation}
	\end{subfigure}
	\caption{$PSF$ approximation typically used in Clark CLEAN}
	\label{gradients:clark}
\end{figure}

An approximation of the full $PSF$ has already been developed for CLEAN: The Clark CLEAN algorithm \cite{clark1980efficient} uses only a window of the full $PSF$ for the deconvolution. Figure \ref{gradients:clark} shows the full $PSF$ and the approximate $PSF$ used typically in Clark CLEAN. During deconvolution, it only uses a window around the center of the full $PSF$. Typically, the sides of the window is $\frac{1}{2}$ of the image size. By using only a $\frac{1}{2} PSF$ window around the center, a Clark CLEAN iteration is significantly faster than standard CLEAN. With $\frac{1}{2} PSF$, Clark CLEAN has to subtract only the $\frac{1}{2} PSF$ window from the residuals, which is 4 times smaller than the full $PSF$.

Using only a fraction fo the true $PSF$ speeds up the deconvolution. But it also introduces sparsity in the deconvolution problem which, to our knowledge, has not been explored for radio interferometers. The full $PSF$ shown in Figure \ref{gradients:clark} has significant values around the center, but they quickly approach zero the further away we move from the center. If we only use a window around the center $\frac{1}{2} PSF$ and set the rest to zero, we are using a sparse $PSF$. For a CLEAN algorithm, the sparse approximated $PSF$ ignores the influence of far away pixel.

The important question is, how small can the center window be? Can we guarantee that the algorithm converges to the same solution, even with an approximated $PSF$? We will test the effect of an approximate $PSF$ on our serial and parallel coordinate descent algorithm in Section \ref{results:gradients}. In this section, we show how we can incorporate an approximate $PSF$ into our coordinate descent algorithms. We discuss only the serial coordinate descent algorithm in this section. The approximation works identical for the parallel coordinate descent algorithm.


\subsection{$PSF$ approximation for the serial coordinate descent algorithm}
The serial coordinate descent algorithm keeps the gradient map, the product $PSF \star PSF$ and the current reconstruction in memory. In each iteration, the algorithm first finds the pixel, which has the maximum possible difference in this iteration. In the second step, it subtracts the product $PSF \star PSF$ at the correct location of the gradient map. The gradient map is now updated for the next iteration of the serial coordinate descent algorithm.

We approximate the $PSF$ by only using a window around the center. Each side is only a fraction of the full $PSF$ size. From now on, we use the method $Cut()$, which cuts out the center window of the $PSF$. If we use a cut fraction of $\frac{1}{4}$, we cut out a window of the $PSF$, each side being  $\frac{1}{4}$ the length of the full $PSF$.

Using an approximate $PSF$ influences three parts of the serial coordinate descent algorithm: The gradient map, the Lipschitz map and the product $PSF \star PSF$. At the beginning of the algorithm, we calculate the gradient map by correlating the dirty image with the $PSF$ ($I_{dirty} \star PSF$) We also calculate the Lipschitz constants for each pixel. The product $PSF \star PSF$ is used to update the gradient map in each iteration. We developed two approximation methods for the serial coordinate descent algorithm. Method 1 is called 'approximate update', and method 2 is called 'approximate deconvolution'.

\subsubsection{Method 1: Approximate update} \label{gradients:methods:update}
The approximate update method only uses the approximate $PSF$ for updating the gradient map. Instead of using the product $PSF \star PSF$, this method uses the product $Cut(PSF) \star Cut(PSF)$ to update the gradient map in each iteration. Figure \ref{gradients:update:figure} shows the effect of the approximation.  

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.245\linewidth}
		\includegraphics[width=\linewidth, clip, trim= 0.25in 0.25in 0.25in 0.25in]{./chapters/03.cd/simulated/psf.png}
		\caption{$PSF$}
	\end{subfigure}
	\begin{subfigure}[b]{0.245\linewidth}
		\includegraphics[width=\linewidth, clip, trim= 0.25in 0.25in 0.25in 0.25in]{./chapters/03.cd/simulated/psfSquared.png}
		\caption{Gradient update}
	\end{subfigure}
	\begin{subfigure}[b]{0.245\linewidth}
		\includegraphics[width=\linewidth, clip, trim= 0.25in 0.25in 0.25in 0.25in]{./chapters/03.cd/simulated/psfCut.png}
		\caption{$Cut(PSF)$}
	\end{subfigure}
	\begin{subfigure}[b]{0.245\linewidth}
		\includegraphics[width=\linewidth, clip, trim= 0.25in 0.25in 0.25in 0.25in]{./chapters/03.cd/simulated/psfSquaredCut.png}
		\caption{Approx. update}
	\end{subfigure}
	
	\caption{Approximation of gradient update.}
	\label{gradients:update:figure}
\end{figure} 

This method uses the full $PSF$ to initialize the gradient and the Lipschitz map. But it only uses an approximation for the update in each iteration of serial coordinate descent. The error we introduce with the approximation gets more severe with more iterations of serial coordinate descent. But the upside is the first iteration in every Major cycle is always identical to the serial coordinate descent algorithm without approximation. This means with enough major cycles, we are guaranteed to converge to the same result.


\subsubsection{Method 2: Approximate deconvolution} \label{gradients:methods:deconv}
This method also uses the approximate gradient update. But instead of initializing the gradient map with the full $PSF$, it also uses the approximate $PSF$ for initializing the gradient and the Lipschitz map. In essence, this method solves an approximate deconvolution problem:

\begin{equation}\label{gradients:method2:objective}
\underset{x}{minimize} \: \frac{1}{2} \left \| I_{dirty} - x * Cut(PSF) \right \|_2^2 + \lambda ElasticNet(x)
\end{equation}

This method does not introduce an error in every serial coordinate descent iteration. But it comes with the downside: It is not guaranteed to converge to the same result as the serial coordinate descent without approximation. It systematically under-estimates the pixel values in the reconstructed image.

To combat the under-estimation of pixel values, we reduce the regularization parameter $\lambda$ for the approximate deconvolution problem. Since we cut off parts of the $PSF$, we also reduce the Lipschitz constant (sum of the squared $PSF$ values) used in the approximate deconvolution. We reduce the $\lambda$ parameter by the same factor that the Lipschitz constant gets reduced. This ensures that the approximate deconvolution and the original deconvolution arrive at the same pixel value for a point source in theory. But it does not completely remove the issue for extended emissions.


\subsubsection{Combining the two approximation methods}
The two approximation methods developed here have opposing downsides: Method 1 is guaranteed to converge to the same result, given enough major cycles, but becomes increasingly inaccurate with more serial coordinate descent iterations. Method 2 does not become increasingly inaccurate, but is not guaranteed to converge to the same result, even with an infinite number of Major cycles.

The obvious question is, what happens when we combine the two approximation method. Indeed, this is our final solution in this project. We start out with method 2, the approximate deconvolution for a few Major cycles, and then switch to method 1, approximate update. When combining both methods, we decided to switch from method 2 to method 1 when the serial or parallel coordinate descent has converged.


\subsection{Implicit path regularization}\label{gradients:pathreg}
When we use an approximate $PSF$, the deconvolution algorithm will at a certain iteration start to include 'side lobes' of the $PSF$. The Figure \ref{gradient:convergence:sidelobe} shows an example of the side lobes we introduce by approximating the $PSF$ with $\frac{1}{2}$ of the center window. At a certain point, the deconvolution with an approximate $PSF$ has to decide whether the emission is real, or whether it is an artifact from the $PSF$ approximation. If the emission is from the $PSF$ approximation, then the deconvolution algorithm should wait for another Major cycle, which will remove the artifact emission.

%re-introduce residuals

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth, clip, trim= 0.25in 0.25in 0.25in 0.25in]{./chapters/03.cd/simulated/psfCut.png}
		\caption{$\frac{1}{2}PSF$ approximation}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth, clip, trim= 0.25in 0.25in 0.25in 0.25in]{./chapters/03.cd/simulated/psfReverseCut.png}
		\caption{$PSF$ Sidelobes}
		\label{gradient:convergence:reverseCut}
	\end{subfigure}
	
	\caption{Maximum sidelobe of the $PSF$ cutoff.}
	\label{gradient:convergence:sidelobe}
\end{figure}

For example: If we have an observation with a single point source in the center, the first iteration of serial coordinate descent will detect the point source, and subtract the approximate gradient update from the gradient map. However, because it is an approximate update, it still leaves significant gradients in the map. But these gradients do not belong to a real emission, but to the $PSF$ sidelobes shown in Figure \ref{gradient:convergence:reverseCut}. The next iteration of serial coordinate descent may detect 'fake' point sources at the significant side lobes of the $PSF$. 

This is a problem for deconvolving an image with the Major cycle. If we do not account for the $PSF$ side lobes, then in each Major cycle the coordinate descent algorithm will include artifacts from the $PSF$ approximation. In the next Major cycle, the serial coordinate descent algorithm has to remove the side lobes from the reconstruction, but this again leaves significant side lobes in the gradient map. This can lead to an oscillation behavior of the deconvolution, where it adds and removes the same side lobes several times over different Major cycles. In extreme cases (for example when we use an aggressive approximation of the $PSF$), this may even lead to a divergence. But even if the deconvolution algorithm converges over several Major cycles, it may waste computing resources on including and excluding $PSF$ side lobes.

To solve this problem, we use the following strategy for our serial and parallel coordinate descent algorithm: We increase the elastic net regularization parameter $\lambda$ until the $PSF$ sidelobes are excluded from the reconstruction. We estimate the side lobes introduced by the $PSF$ approximation, and estimate by how much the parameter $\lambda$ has to be increased in this Major cycle. The serial and parallel coordinate descent algorithm reconstructs the image with the current $\lambda$, and lets the Major cycle remove the side lobes. It then estimates the current $PSF$ side lobes for the next Major cycle, sets a lower regularization parameter $\lambda$ and again deconvolves the image.

This is known as a path regularization in optimization. We let our serial and parallel coordinate descent algorithm converge on intermediate solution, decrease the $\lambda$ parameter and use the intermediate solution as a 'warm start'. Coordinate descent methods may benefit from path regularization\cite{friedman2010regularization}. Converging on all intermediate solutions may result in a lower wall-clock time than converging directly on the final solution.

We use the path regularization to stop the algorithm from wasting computing resources on side lobes. There may be different strategies that result in an overall lower wall-clock time for the serial and parallel coordinate descent algorithm, but they were not explored in this project. We set the regularization parameter $\lambda$ for each Major cycle according to the following estimate:

\begin{equation}
\begin{split}
maxSidelobe &= Max(PSF - Cut(PSF)) \\
gradients &= residuals \star PSF \\
\lambda_{cycle} &= \frac{Max(gradients) * maxSidelobe}{\alpha}\\
\lambda_{cycle} &= Max(\lambda, \lambda_{cycle})
\end{split}
\end{equation}

We calculate the maximum side lobe of the $PSF$ approximation. We then multiply the maximum side lobe with the maximum gradient. This is an estimate of the largest gradient value, which gets left in the gradient map by the $PSF$ approximation. We then set the $\lambda_{cycle}$ parameter to exclude all gradients equal or smaller that gradient magnitude. The maximum of the gradient map decreases over every Major cycle, which leads to a decreasing $\lambda_{cycle}$ until we reached the target value $\lambda$.

This estimate works, but it has one problem for radio interferometric imaging: It does not account for extended emissions. Since they have non-zero pixel values close to each other, their $PSF$ side lobes also overlap. Meaning the $PSF$ side lobes of extended emissions are higher than we estimated. This is why we added a correction factor which estimates how much the maximum in the gradient map is point-source-like:

\begin{equation}
\begin{split}
maxSidelobe &= Max(PSF - cut(PSF)) \\
gradients &= residuals \star PSF \\
\textbf{correction} &= Max \left [1, \frac{Max(gradients)}{Max(residuals) * Lipschitz} \right ] \\
\lambda_{cycle} &= \frac{ Max(gradients) * maxSidelobe * correction}{\alpha}\\
\lambda_{cycle} &= Max(\lambda, \lambda_{cycle})
\end{split}
\end{equation}

It the same estimate as before, except for the correction factor. The correction factor is 1 if the maximum in the gradient map is a point source, and $1 <$ if the maximum in the gradient map is more like an extended emission. The correction factor is based on the following observation: If the image only contains point sources, then the maximum of the gradient map should be equal the maximum of the residuals times the Lipschitz constant. But if it is an extended emission, the maximum of the gradient map will be significantly larger.

This is the estimate we use for the regularization parameter $\lambda_{cycle}$ for each Major cycle. The parameter $\lambda_{cycle}$ decreases over each Major cycle, resulting in an implicit path regularization for our serial coordinate descent method.
