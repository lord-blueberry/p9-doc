\section{The image reconstruction problem of radio interferometers}
\begin{figure}[htp]
	% preliminary
	\sbox\twosubbox{%
		\resizebox{\dimexpr.8\textwidth-1em}{!}{%
			\includegraphics[height=3cm]{./chapters/01.intro/first.png}%
			\includegraphics[height=3cm]{./chapters/01.intro/first.png}%
		}%
	}
	\setlength{\twosubht}{\ht\twosubbox}
	
	% typeset
	\centering
	\subcaptionbox{Measurements of the interferometer in the Fourier space.\label{intro0:inversefig:uvspace}}{%
		\includegraphics[height=\twosubht]{./chapters/01.intro/first.png}%
	}\quad
	\subcaptionbox{Observed image of the sky, showing two stars.\label{intro0:inversefig:reconstruction}}{%
		\includegraphics[height=\twosubht]{./chapters/01.intro/first.png}%
	}
	\caption{The image reconstruction problem, the observed image has to be reconstructed from the Fourier measurements.}\label{intro0:inversefig}
\end{figure}

In Astronomy, one goal is to find ever smaller objects in the sky. For this purpose, we build instruments with higher angular resolution. The instruments angular resolution depends on two factors: On the diameter of the antenna-dish or mirror, and on the observed wavelength. With longer wavelengths we need bigger dishes/mirrors to achieve a similar angular resolution. 

This is an issue for Radio Astronomy. The long radio wavelengths require huge dishes for a high angular resolution. Of course there is a practical limit on the antenna-dish diameter we can build. The famous Arecibo observatory is one of the largest single-dish radio telescopes with a diameter of 305 meters. Antennas with such a large diameter become difficult to steer accurately, let alone the construction costs. We have reached the practical limits of single-dish telescopes. If we require higher angular resolution, we need to look at another type of instrument: The radio interferometer. They use several smaller antennas together, acting like a single large dish. An interferometer can achieve angular resolutions which are comparable to dishes with a diameter of several kilometers.

But there are drawbacks: The interferometer does not measure the sky in pixels. It measures the amplitude and phase of Fourier components at a given $u$ and $v$ location\footnote{$u$ and $v$ are the axis in Fourier space}. The observed image has to be reconstructed from the measurements. The figure \ref{intro0:inversefig} shows an example of the image reconstruction problem. The figure \ref{intro0:inversefig:uvspace} shows the measurements in the Fourier space, and the figure \ref{intro0:inversefig:reconstruction} shows the observed image of the sky, with two stars close to each other. The image reconstruction has to find the observed image \ref{intro0:inversefig:reconstruction} from the measurements \ref{intro0:inversefig:uvspace}. 

At first glance, we might believe that the image reconstruction is trivial: The interferometer measures Fourier components, and efficient algorithms for the inverse Fourier transforms are well-known. However, two properties of the measured Fourier components make the image reconstruction difficult: The measurements are both noisy and incomplete.

The atmosphere of the earth is one source that introduces noise. It adds noise to the amplitude and phase of each measured Fourier component. The atmosphere changes over time and can under the right circumstances introduce a high level of noise compared to the signal. The image reconstruction should be able to find the observed image from potentially very noisy Fourier measurements.

The interferometer measures an incomplete set of Fourier components. Note that the figure \ref{intro0:inversefig:uvspace} shows the Fourier space, which has missing components. The interferometer can only measure a limited set of Fourier components. The reconstruction algorithm has to find the observed image even though important Fourier components are missing from the measurements.

These two difficulties, the noise and the incomplete measurements, lead to the fact that there are many different candidate images that fit the measurements. From the measurements alone, we cannot decide which candidate is the truly observed image. However, we have additional knowledge that simplifies the problem: We know it is an image of the sky, which consists of stars, hydrogen clouds, etc. By including prior knowledge in the reconstruction, we can find the most likely image given the measurements. 

The question remains is: How close is the most likely image to the observed one? Is exact reconstruction possible where the most likely and observed image are equal? Surprisingly the answer is yes. In theory, it is possible to even create a super-resolved reconstruction (where we retrieve an image below the accuracy limit of the instrument)\cite{candes2006robust,donoho2006compressed}, and was shown in practice on low noise measurements\cite{dabbech2018cygnus, dabbech2015moresane}. However, not all algorithms perform equally well when the noise level in the measurements is high. Also, computing resources required for each algorithm can vary significantly. In short, a reconstruction algorithm has three opposing goals:
\begin{enumerate}
	\item Produce a reconstruction with the highest possible resolution from the measurements.
	\item Robust against even heavy noise in the measurements.
	\item Use as few computing resources as possible.
\end{enumerate}

No reconstruction algorithm performs equally well on all three goals. The CLEAN algorithm\cite{hogbom1974aperture, rau2011multi} has shown to be robust against heavy noise and, depending on the observation, uses fewer computing resources than other algorithms\cite{offringa2017optimized}. It is one of the oldest algorithms still in use today. As such, it was developed before the advent of distributed and gpu-accelerated computing.



T

There is no reconstruction algorithm that has the optimal trade-off between all three goals. It is an active field of research.

To complicate things further, newly constructed radio interferometers pose the reconstruction problem on a big data scale. The recently finished MeerKAT radio interferometer produces roughly 80 million Fourier measurements each second.
We need to distribute the image reconstruction. This is an active field of research.
Research into how we can perform the image reconstruction in a

Part of data modelling. What is the prior knowledge

and Optimization algorithm, which finds the optimum trade-off

The ideal reconstruction algorithm not only achieves all three opposing goals, but is also distributable in a super-computer environment, preferably on the GPU. This is a tall order. So far, the go-to reconstruction algorithm CLEAN was performing its numerical optimization on a single machine. The new data volume raises the need for distributed and GPU-Accelerated optimization algorithms.

We explore coordinate Descent based methods

This Project focuses on the third point, distributed image reconstruction with real-world meerkat observations
Received from SARAO for the purpose of algorithmic validation.
