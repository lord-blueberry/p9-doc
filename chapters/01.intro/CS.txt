\section{Introduction to radio interferometric imaging}\label{radio}
%This Section gives an introduction to radio interferometric imaging. We introduce how the interferometer measures visibilities, what problems arise and how reconstruction algorithms solve them. 

A radio interferometer consists of several antennas. Each antenna pair measures a visibility in Fourier space. Each measurement consists of an amplitude and phase at a location at a $u$ and $v$  location. The distance between the antennas, which we call the baseline, defines what point in the Fourier space gets sampled. The Figure \ref{radio:sampling:ants} shows the antenna layout of the MeerKAT radio interferometer, and the Figure \ref{radio:sampling:pattern} shows the measurement points in Fourier space. Short baselines sample points close to the origin, and contain the low-frequency Fourier components. They contain information about large areas of the images. Longer baselines measure points further away from the origin. They sample the high-frequency Fourier components. They contain information about edges, and other small structures in the image.


\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{./chapters/01.intro/aperture/ants.png}
		\caption{Antenna layout.}
		\label{radio:sampling:ants}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{./chapters/01.intro/aperture/snapshot.png}
		\caption{Visibility sampling pattern.}
		\label{radio:sampling:pattern}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.47\linewidth}
		\includegraphics[width=\linewidth]{./chapters/01.intro/aperture/frequencies.png}
		\caption{Visibilities added from multiple channels.}
		\label{radio:sampling:freq}
	\end{subfigure}
	\begin{subfigure}[b]{0.47\linewidth}
		\includegraphics[width=\linewidth]{./chapters/01.intro/aperture/timesteps.png}
		\caption{Visibilities added from multiple timesteps.}
		\label{radio:sampling:time}
	\end{subfigure}
	
	\caption{Sampling regime of the MeerKAT radio interferometer.}
	\label{intro:sampling}
\end{figure}

The sampling pattern of the MeerKAT interferometer is not uniform in the Fourier space. We have areas which are densely sampled, and areas which are sparsely sampled. Note that we only have a few samples of the high-frequency Fourier components. We are missing measurements from a large portion of the Fourier space.

Radio interferometers use two "tricks" to measure more points in the Fourier space. Radio interferometers measure the sky in different radio channels simultaneously. We can add the visibility measurements from different channels together, shown in Figure \ref{radio:sampling:freq}. Each channel measures the Fourier space using the same pattern, but scaled by the radio frequency. 

The second trick is to use the earth's rotation to sample different points in the Fourier space. The earth's rotation also rotates the sampling pattern in Fourier space, shown in Figure \ref{radio:sampling:time}, and we can sample the Fourier space at new locations.

The MeerKAT radio interferometer measures 2016 visibilities, for each channel, at each timestep. It has 20 thousand radio channels. The time resolution can be as low as half a second. This results in roughly 80 million visibility measurements per second. In radio astronomy, we want to reconstruct several hours worth of visibility measurements. 
%GB and TB of data

\begin{figure}[htp]
	% preliminary
	\sbox\twosubbox{%
		\resizebox{\dimexpr.9\textwidth-1em}{!}{%
			\includegraphics[height=3cm]{./chapters/01.intro/meerkat_uv2.png}%
			\includegraphics[height=3cm]{./chapters/01.intro/mk2/clean.png}%
		}%
	}
	\setlength{\twosubht}{\ht\twosubbox}
	
	% typeset
	\centering
	\subcaptionbox{Real-world visibilities combined from different channesl and timesteps.\label{intro:inversefig:uvspace}}{%
		\includegraphics[height=\twosubht]{./chapters/01.intro/meerkat_uv2.png}%
	}\quad
	\subcaptionbox{Reconstruction of the visibility measurements.\label{intro:inversefig:reconstruction}}{%
		\includegraphics[height=\twosubht]{./chapters/01.intro/mk2/clean.png}%
	}
	\caption{Example of an image reconstruction for Fourier measurements of the MeerKAT radio interferometer}\label{intro:inversefig}
\end{figure}

It is easy to see that the visibility measurements from MeerKAT quickly fills up the hard disk and the Fourier space with samples. The Figure \ref{intro:inversefig:uvspace} shows a fraction of the visibility samples from a real-world observation. The visibilities are combined from multiple channels and multiple timesteps. Although we have a large number of visibilities, we still have areas of the Fourier space without a sample. Although we have a large number of samples, the visibilities are still an incomplete. From the measurements alone, we cannot reconstruct the image shown in Figure \ref{intro:inversefig:uvspace}.

This is known as an ill-posed inverse problem in the literature. A problem is considered ill-posed when:
\begin{enumerate}
	\item No solution exists.
	\item There are solutions, but no unique solution exists.
	\item The solution behavior does not change continuously with the initial condition (For example: a small change in the measurements lead to a very different reconstructed image).
\end{enumerate}
Image reconstruction for radio interferometer is an inverse problem, because we want to find the image which the interferometer observed in Fourier space. It is ill-posed in general, because there are many different images that fit the measurements.

Note that we can reduce the resolution of the reconstructed image until the problem becomes well-posed. The Nyquist-Shannon sampling theorem states for the case of radio interferometers: The highest highest Fourier-frequency we measure should be more than twice the highest frequency in the image. The center of the Fourier space in Figure \ref{intro:inversefig:uvspace} is densely sampled. We can reconstruct a low-resolution image that only needs the information from the densely sampled center.

However, this would reduce the effective resolution of the reconstruction. If we can solve the ill-posed inverse problem, we would be able to retrieve the observed image at a higher resolution than possible with the Nyquist-Shannon sampling theorem. As it turns out, this is possible to solve the ill-posed inverse problem by including prior information. We use a numerical optimization algorithm and find the optimal image, which is both consistent with the measurements and consistent with our prior knowledge. This is known in signal processing as compressed sensing \cite{candes2006robust,donoho2006compressed} in the literature. The theory of Compressed Sensing shows that, under the right prior information, we are guaranteed to reconstruct the observed image at a higher resolution than under the Nyquist-Shannon sampling theorem.

%In Section \ref{intro2:ill-posed}, we introduce the Compressed Sensing sampling theorem and show how it works in the case of radio interferometric image reconstruction. The Section \ref{intro2:rec} shows how we can use the theory to create a reconstruction algorithm in practice. But first, we dive deeper into the odds and ends of radio interferometry. 

\subsection{The theory of Compressed Sensing}\label{radio:cs}
We introduce the theory of Compressed Sensing for the problem of radio interferometric image reconstruction. As we have mentioned compressed sensing image reconstruction involves a numerical optimization algorithm to find the optimal solution which is consistent with our measurements and consistent with our prior knowledge. As we will see later, the theory of compressed sensing guarantees us exact reconstruction under certain assumptions. 

Let us formulate the image reconstruction as an optimization problem.The image reconstruction wants to to find the image which is as close to the measurements as possible. Or more formally, we want to minimize the euclidean distance between the visibility measurements $V$ and the reconstructed image $x$. We write it as an objective function:

\begin{equation}\label{radio:cs:l2}
\underset{x}{minimize} \: \left \| V - MFx \right \|_2^2
\end{equation}

Where $F$ is the Fourier transform matrix and $M$ is the "masking" matrix. The Fourier matrix transforms the reconstructed image to visibilities, and the masking matrix zeros out all visibilities that the radio interferometer cannot measure.

We can reconstruct the image by finding the optimum of the objective function \eqref{radio:cs:l2}. The objective function is convex, meaning it has only one global minimum, and we can use the class of convex optimization algorithms to search the minimum. However, our measurements $V$ are incomplete, meaning we do not have all the data we need for reconstruction. This means our objective function \eqref{radio:cs:l2} does not "point" to the observed image. It still has a global minimum, but observed image is not guaranteed to be near the global minimum.

A side note: We are guaranteed to find the observed image at the minimum of \eqref{radio:cs:l2} is when the measurements fulfill the Nyquist-Shannon sampling theorem. In that case, we can find the minimum by calculating the inverse Fourier transform: $x = F^{-1}V$. We can still calculate the inverse Fourier transform when we are dealing with incomplete measurements, but it does not result in the observed image.

However, the objective \eqref{radio:cs:l2} only includes information about the measurements. As we have mentioned before, we have prior knowledge about the image. We know it is likely to contain stars. Stars are radio-emissions which are concentrated around a single pixel. In that case, most pixels of the image will be zero, except for the locations where the interferometer has located stars. In other words, we know that the image is sparse. We can add a regularization to the objective function \eqref{radio:cs:l2} and force the reconstructed image to be sparse. This results in the modified objective function:

\begin{equation}\label{radio:cs:lasso}
\underset{x}{minimize} \: \left \| V - MFx \right \|_2^2 + \lambda \left \| x \right \|_1
\end{equation}

Note the two terms in the objective \eqref{radio:cs:lasso}: We have the same term from our measurements, which we call the "data term". But we also have an additional "regularization term", which is the L1 norm\footnote{Sum of absolute values of the pixels} and forces our reconstruction to be sparse. The parameter $\lambda$ represents how much emphasis we put on the regularization. The new objective function is still convex, it still has a global minimum. The regularization term simply shifted the global minimum to a different location when compared to the first objective \eqref{radio:cs:l2}. Now the question is: How likely is our modified objective \eqref{radio:cs:lasso} to point at the observed image? 

If the image truly only contains stars, the new objective practically always leads to the observed image.
We do exact reconstruction.
Even though we do have incomplete measurements. Intuitively, we append the missing information with prior knowledge.

Exact reconstruction depends on how well the regularization models the image content. For example if it only contains stars, then the L1 norm $\left \| x \right \|_1$ is a good regularization. The smallest penalties have the reconstructions with the smallest number of point sources. For extended emissions however, we have a large number of non-zero pixels and the L1 norm is insufficient. It puts a too-high penalty on images with extended emissions.
Data modeling task

How many visibility samples are necessary for exact reconstruction? . Based on assumptions of the matrix product $MF$. Hard to prove for any given observation. The visibility samples are given, we cannot change them. H
The theory of compressed sensing tells us why the observed image at the minimum of \eqref{radio:cs:lasso}
Hard to prove in reality \cite{natarajan2014computational}. So we do not know if 

Compressed sensing reconstruction: An objective function, a regularization and a numerical optimization algorithm.
We cannot change them. We focus on the numerical optimization algorithm. Our task is to solve the problem as fast as possible.

The theory of Compressed Sensing tells us that it depends on the image content of the observed image. If it only consists of stars, we are practically guaranteed to find the observed image at the minimum of \eqref{radio:cs:lasso}, even though we are dealing with incomplete measurements.

We use the words 'practically guaranteed' because the theory of Compressed Sensing does give us guarantees to find the observed image at the minimum of \eqref{radio:cs:lasso} under certain assumptions. The issue is these assumptions are hard to verify for any given reconstruction problem . One of the central assumption is that the regularization is a good model for the image content.

In reality, it is often easier to empirically show that the regularization works. Recent development, by creating a super-resolved\footnote{The radio interferometer also has a resolution limit. Super-resolved reconstructions were able to find structures which are smaller than the limit of the instrument.} reconstruction from visibility measurements \cite{dabbech2018cygnus}. The assumptions do have important implications for instrument design. This project however is focused on the numerical optimization algorithm. We do not have an influence on the visibility measurements, for our intends and purposes, the measurements are fixed.



\subsubsection{Exact reconstruction in theory}\label{radio:cd:intuitive}
What is exact reconstruction: When the most likely image is equal to the observed image. 

Let us go back to our example of an image containing only stars. Let us say it has $256^2$ pixels and contains $S = 10$ stars. But we do not know how many it has, where they are, nor their intensity (pixel value). We just know there are only stars in the image. 

If we measure the image with a single-dish instrument, we measure every pixel after each other. Note that, because we know the image contains only stars, we already know most pixels will be zero. When the single-dish measures a zero pixel, all we learn is that there is no star at this location. We only learn something vital when the single-dish instrument hits one of the 10 stars. We learn little when the instrument measures a zero pixel, and a lot when it measures a pixel with a star. On average over all pixel measurements, we learn little about the image.

When we measure the image with a radio interferometer, we measure visibilities (Fourier components) of the image. Remember that a single visibility is a measurement over the whole image. Every pixel of the image has contributed to the amplitude and phase of the visibility. Every visibility measurement contains some information about the 10 stars in the image. On average, each visibility measurement contains more information about the stars than the average pixel measurement of the single-dish instrument. This means a set of Visibility measurements may contain all the information in the image, even though it has magnitudes fewer measurements than the single-dish instrument.

Now the question is, at what point do we know the visibility measurements contain all the information in the image. The answer is: As soon as we have a unique minimum to \eqref{radio:cs:lasso}, it guaranteed to be the observed image. At what point there is a unique minimum depends on two components: It depends on the matrix product $MF$ of the objective \eqref{radio:cs:lasso} and on the number of stars in the image. If we want to be sure that the image we reconstructed is the truly observed one, we have to prove that there is no solution to \eqref{radio:cs:lasso} that has fewer non-zero components. This is done with the Restricted Isometry Property (RIP) \cite{candes2006robust,donoho2006compressed}.

For compressed sensing, we require the matrix product $MF$ to fulfill the RIP. The RIP is a measure of how much a random subset of columns correlate with each other (Or in our case: How much a random subset of pixels correlate with each other). 
In our example with an image containing 10 stars, it means that each star is uncorrelated from each other.
If we have found a solution with 10 stars, the RIP is the tool to prove that there exists no solution with fewer stars. Therefore the solution is optimal.

How we can be sure that the matrix product $MF$ fulfills the RIP? Remember that the matrix product $MF$ arises from where we sample the visibilities in the Fourier space. If we randomly sample the visibilities, we are almost guaranteed to have an $MF$ that fulfills the RIP\cite{haviv2017restricted}.


\subsubsection{Exact reconstruction in practice}
In theory we can guarantee exact reconstruction if the matrix product $MF$ fulfills the RIP and if the image contains stars. In practice, we do not know if the matrix product $MF$ fulfills the RIP. Calculating the RIP for a given matrix is often more difficult than finding a solution \cite{natarajan2014computational}. Also, the RIP may be too restrictive. Exact reconstruction is also possible under less strict conditions\cite{candes2011probabilistic} than defined by the RIP. In short, proving that we reconstructed the observed image is hard in the real-world.

Furthermore the image may not contain solely of stars. Radio interferometers also measure hydrogen gas clouds and supernova remnants which span a large area of pixels. The 

 Specialized wavelets for radio astronomy \cite{starck2015starlet}.

 The pattern is given by the antenna layout. And secondly, the image does not only contain stars. It also contains extended emissions like hydrogen clouds and supernova remnants.

The 
Interferometer does not sample randomly, and does not only contain stars.


At what point we fulfill the RIP also depends on the number of stars. Intuitively this makes sense. We do not need as many data if the image is simple.
Note on sparseness: also possible in different spaces. Funny thing, when we find a space which the image is even more sparse, we need even less visibility measurements for reconstruction.


 
What to do about extended emissions. It is a data modelling task, how do we find good regularization that leads to the sparset result possible. Problem of validation, we do not know the best regularization beforehand. We can only choose one that works "well.

The theory of compressed sensing gives us a framework. There is a data modelling task, and a task for finding efficient algorithms.

So there is a data modelling task in finding a good sparse prior.
We also do not know the proper sparse space in which radio interferometric images. We know several spaces, Curvelets \cite{starck2003astronomical} Starlets \cite{starck2015starlet}, Daubechies wavelets \cite{carrillo2012sparsity}. As of the time of writing, it is currently unknown which leads to the best reconstruction.
We can also learn dictionaries.


%\subsubsection{General Compressed Sensing reconstruction formulation}
%Use everything with the L1 norm. More general formulation
%$F$ is fixed, because we cannot change the interferometer.
%We do just need a sparse space.